{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff6d511c-c014-4d96-98da-d5b84bb6c082",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saiet\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated and will be removed in a future release\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from skimage.filters import sobel\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from skimage.measure import shannon_entropy\n",
    "from tqdm import tqdm\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b97720f-75b9-4330-adf6-11436aa7e86a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'total_segments/thermal/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_segments/thermal/\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'total_segments/thermal/'"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"total_segments/thermal/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26db7f21-beb0-4469-aad9-820ed4068722",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3eebb4-b54d-4942-a747-777c8ba89347",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = []\n",
    "train_labels = [] \n",
    "\n",
    "for directory_path in glob.glob(\"total_segments/thermal/*\"):\n",
    "    label = os.path.basename(directory_path)  # Get the folder name as label\n",
    "    for img_path in glob.glob(os.path.join(directory_path)):  # Corrected wildcard\n",
    "        img = cv2.imread(img_path, 0)  # Read the image in grayscale mode\n",
    "        if img is not None:  # Check if image is loaded successfully\n",
    "            img = cv2.resize(img, (SIZE, SIZE))  # Resize the image\n",
    "            train_images.append(img)\n",
    "            train_labels.append(label)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)\n",
    "train_labels_p = np.array([name.split('_')[0] for name in train_labels])\n",
    "\n",
    "print(train_labels_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b628025-ef6c-4534-935b-2420ecefd129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e9ee3d-8e6f-4d25-8e26-7fc05c8beb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "le.fit(train_labels_p)\n",
    "train_labels_encoded = le.transform(train_labels_p)\n",
    "\n",
    "x_train, y_train = train_images, train_labels_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a696075b-c2cf-414b-bb82-14664978cb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971e1cea-4b8d-4202-bcaf-24b456b48517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(dataset):\n",
    "    image_dataset = pd.DataFrame()\n",
    "    for image in tqdm(range(dataset.shape[0]),desc=\"extracing GLCM features\"):  #iterate through each file \n",
    "        #print(image)\n",
    "        \n",
    "        df = pd.DataFrame()  #Temporary data frame to capture information for each loop.\n",
    "        #Reset dataframe to blank after each loop.\n",
    "        \n",
    "        img = dataset[image, :,:]\n",
    "    ################################################################\n",
    "    #START ADDING DATA TO THE DATAFRAME\n",
    "  \n",
    "                \n",
    "         #Full image\n",
    "        #GLCM = greycomatrix(img, [1], [0, np.pi/4, np.pi/2, 3*np.pi/4])\n",
    "        GLCM = graycomatrix(img, [1], [0])       \n",
    "        GLCM_Energy = graycoprops(GLCM, 'energy')[0]\n",
    "        df['Energy'] = GLCM_Energy\n",
    "        GLCM_corr = graycoprops(GLCM, 'correlation')[0]\n",
    "        df['Corr'] = GLCM_corr       \n",
    "        GLCM_diss = graycoprops(GLCM, 'dissimilarity')[0]\n",
    "        df['Diss_sim'] = GLCM_diss       \n",
    "        GLCM_hom = graycoprops(GLCM, 'homogeneity')[0]\n",
    "        df['Homogen'] = GLCM_hom       \n",
    "        GLCM_contr = graycoprops(GLCM, 'contrast')[0]\n",
    "        df['Contrast'] = GLCM_contr\n",
    "\n",
    "\n",
    "        GLCM2 = graycomatrix(img, [3], [0])       \n",
    "        GLCM_Energy2 = graycoprops(GLCM2, 'energy')[0]\n",
    "        df['Energy2'] = GLCM_Energy2\n",
    "        GLCM_corr2 = graycoprops(GLCM2, 'correlation')[0]\n",
    "        df['Corr2'] = GLCM_corr2       \n",
    "        GLCM_diss2 = graycoprops(GLCM2, 'dissimilarity')[0]\n",
    "        df['Diss_sim2'] = GLCM_diss2       \n",
    "        GLCM_hom2 = graycoprops(GLCM2, 'homogeneity')[0]\n",
    "        df['Homogen2'] = GLCM_hom2       \n",
    "        GLCM_contr2 = graycoprops(GLCM2, 'contrast')[0]\n",
    "        df['Contrast2'] = GLCM_contr2\n",
    "\n",
    "        GLCM3 = graycomatrix(img, [5], [0])       \n",
    "        GLCM_Energy3 = graycoprops(GLCM3, 'energy')[0]\n",
    "        df['Energy3'] = GLCM_Energy3\n",
    "        GLCM_corr3 = graycoprops(GLCM3, 'correlation')[0]\n",
    "        df['Corr3'] = GLCM_corr3       \n",
    "        GLCM_diss3 = graycoprops(GLCM3, 'dissimilarity')[0]\n",
    "        df['Diss_sim3'] = GLCM_diss3       \n",
    "        GLCM_hom3 = graycoprops(GLCM3, 'homogeneity')[0]\n",
    "        df['Homogen3'] = GLCM_hom3       \n",
    "        GLCM_contr3 = graycoprops(GLCM3, 'contrast')[0]\n",
    "        df['Contrast3'] = GLCM_contr3\n",
    "\n",
    "        GLCM4 = graycomatrix(img, [0], [np.pi/4])       \n",
    "        GLCM_Energy4 = graycoprops(GLCM4, 'energy')[0]\n",
    "        df['Energy4'] = GLCM_Energy4\n",
    "        GLCM_corr4 = graycoprops(GLCM4, 'correlation')[0]\n",
    "        df['Corr4'] = GLCM_corr4       \n",
    "        GLCM_diss4 = graycoprops(GLCM4, 'dissimilarity')[0]\n",
    "        df['Diss_sim4'] = GLCM_diss4       \n",
    "        GLCM_hom4 = graycoprops(GLCM4, 'homogeneity')[0]\n",
    "        df['Homogen4'] = GLCM_hom4       \n",
    "        GLCM_contr4 = graycoprops(GLCM4, 'contrast')[0]\n",
    "        df['Contrast4'] = GLCM_contr4\n",
    "        \n",
    "        GLCM5 = graycomatrix(img, [0], [np.pi/2])       \n",
    "        GLCM_Energy5 = graycoprops(GLCM5, 'energy')[0]\n",
    "        df['Energy5'] = GLCM_Energy5\n",
    "        GLCM_corr5 = graycoprops(GLCM5, 'correlation')[0]\n",
    "        df['Corr5'] = GLCM_corr5       \n",
    "        GLCM_diss5 = graycoprops(GLCM5, 'dissimilarity')[0]\n",
    "        df['Diss_sim5'] = GLCM_diss5       \n",
    "        GLCM_hom5 = graycoprops(GLCM5, 'homogeneity')[0]\n",
    "        df['Homogen5'] = GLCM_hom5       \n",
    "        GLCM_contr5 = graycoprops(GLCM5, 'contrast')[0]\n",
    "        df['Contrast5'] = GLCM_contr5\n",
    "        \n",
    "        #Add more filters as needed\n",
    "        #entropy = shannon_entropy(img)\n",
    "        #df['Entropy'] = entropy\n",
    "\n",
    "        \n",
    "        #Append features from current image to the dataset\n",
    "        image_dataset = pd.concat([image_dataset, df], ignore_index=True)\n",
    "        \n",
    "    return image_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bbee73-6f54-4731-9ca0-25fd53989fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features = feature_extractor(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f16fefd-0179-4523-a0ca-3d7ec632dd30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe8e350-3574-4d26-b6f2-b4e3d81734be",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54be7d84-7c30-4b12-ae35-69abe6dfb4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_glcm=image_features.drop([\"Corr4\",\"Diss_sim4\",\"Contrast4\",\"Corr5\",\"Diss_sim5\",\"Homogen3\",\"Homogen4\",\"Homogen5\",\"Contrast5\",\"Energy5\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d3540b-74b1-4c82-b4b2-ca7ab0a4c271",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_glcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c9b2ce-6ece-4cca-a4f3-cc9bcb826d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load YOLOv8 model\n",
    "\n",
    "model_detect = YOLO(\"runs/detect/train57/weights/best.pt\")\n",
    "\n",
    "# Choose the layer to hook\n",
    "features = []\n",
    "def hook(module, input, output):\n",
    "    features.append(output)\n",
    "\n",
    "layer_to_hook = model_detect.model.model[-2]  # You can change this index as needed\n",
    "hook_handle = layer_to_hook.register_forward_hook(hook)\n",
    "\n",
    "# Folder path\n",
    "folder_path = \"total_segments/normal\"\n",
    "data = {}\n",
    "\n",
    "# Loop through all images\n",
    "for filename in tqdm(os.listdir(folder_path),desc=\"extracting yolo features\"):\n",
    "    if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Preprocess image\n",
    "        im = cv2.imread(image_path)\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "        im = cv2.resize(im, (640, 640))\n",
    "        im = im.astype(np.float32) / 255.0\n",
    "        im = torch.from_numpy(im.transpose(2, 0, 1)).unsqueeze(0)\n",
    "        \n",
    "        features.clear()  # Clear previous feature\n",
    "        with torch.no_grad():\n",
    "            _ = model_detect.model(im)\n",
    "        \n",
    "        # Extract and process features\n",
    "        feat_tensor = features[0]\n",
    "        feat_vector = torch.nn.functional.adaptive_avg_pool2d(feat_tensor, 1).view(feat_tensor.shape[0], -1)\n",
    "        \n",
    "        # Save in dictionary\n",
    "        data[filename] = feat_vector.squeeze().numpy()\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame.from_dict(data, orient='index')\n",
    "\n",
    "# Optional: Save to CSV\n",
    "# df.to_csv(\"yolo_features.csv\")\n",
    "\n",
    "print(df.shape)\n",
    "print(df.head())\n",
    "\n",
    "# Remove the hook\n",
    "hook_handle.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd40871-4f68-4de9-997a-a8bce3826935",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yolo = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9d60b4-9bb2-4bf3-b3cc-39d319d30ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_yolo.index)\n",
    "print(df_glcm.index)\n",
    "df_yolo = df_yolo.reset_index(drop=True)\n",
    "df_glcm = df_glcm.reset_index(drop=True)\n",
    "df_combined = pd.concat([df_yolo, df_glcm], axis=1)\n",
    "\n",
    "print(df_combined.shape)\n",
    "print(df_combined.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7ef7e0-c1e8-498d-831c-da4e5ddc922f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047e39b5-d910-410c-baf1-2c5e4eb4f725",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined[\"Target\"] = train_labels_encoded\n",
    "try:\n",
    "    df_combined = df_combined.drop([\"index\"],axis=1)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2cada0-612e-473a-8a0e-9f859bb675c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71325f01-0511-4956-a9e7-21cb3d8c5dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.to_csv(\"combined_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56dfa63-7cc9-445b-9175-b5f825d08ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "sender = \"126156188@sastra.ac.in\"\n",
    "app_password = \"ixtc oceh zzre sjgc\"\n",
    "receiver = \"126156188@sastra.ac.in\"\n",
    "\n",
    "msg = MIMEText(\"âœ… Your code has finished running!\")\n",
    "msg[\"Subject\"] = \"YOLO Notification\"\n",
    "msg[\"From\"] = sender\n",
    "msg[\"To\"] = receiver\n",
    "\n",
    "with smtplib.SMTP_SSL(\"smtp.gmail.com\", 465) as server:\n",
    "    server.login(sender, app_password)\n",
    "    server.send_message(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fc470f-ee66-4287-b10a-f32441fe58a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(le, \"label_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3516e95-dd2a-4a95-ac42-3d222c3c5a2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
