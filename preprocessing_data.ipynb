{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67f2e4b4-3831-4ab3-9c17-b993e3fd6414",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Moving files to images/Training_data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1836/1836 [00:02<00:00, 626.18it/s]\n",
      "Moving files to images/Validation_data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 229/229 [00:00<00:00, 608.04it/s]\n",
      "Moving files to images/Testing_data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 235/235 [00:00<00:00, 535.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset split into Train, Validation, and Test sets successfully!\n",
      "ðŸ”¹ Train: 1836 images\n",
      "ðŸ”¹ Val: 229 images\n",
      "ðŸ”¹ Test: 229 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define paths\n",
    "DATASET_DIR =  \"Data/dataset2\"\n",
    "\n",
    "ANNOTATIONS_DIR = \"VOC_lab2\"  # Folder with YOLO TXT labels\n",
    "\n",
    "# Define new dataset split folders\n",
    "TRAIN_DIR = \"images/Training_data\"\n",
    "VAL_DIR = \"images/Validation_data\"\n",
    "TEST_DIR = \"images/Testing_data\"\n",
    "\n",
    "TRAIN_LABELS = \"labels/Training_data\"\n",
    "VAL_LABELS = \"labels/Validation_data\"\n",
    "TEST_LABELS = \"labels/Testing_data\"\n",
    "\n",
    "# Ensure folders exist\n",
    "for folder in [TRAIN_DIR, VAL_DIR, TEST_DIR, TRAIN_LABELS, VAL_LABELS, TEST_LABELS]:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "# Get all image files\n",
    "image_files = [f for f in os.listdir(DATASET_DIR) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "random.shuffle(image_files)  # Shuffle to randomize split\n",
    "\n",
    "# Define split numbers (Modify as needed)\n",
    "num_train = 1836  # 70% for training\n",
    "num_val = 229    # 20% for validation\n",
    "num_test = 229  # Remaining for test\n",
    "\n",
    "# Assign images to each set\n",
    "train_images = image_files[:num_train]\n",
    "val_images = image_files[num_train:num_train + num_val]\n",
    "test_images = image_files[num_train + num_val:]\n",
    "\n",
    "# Function to move images & annotations\n",
    "def move_files(image_list, dest_img_folder, dest_label_folder):\n",
    "    for img_file in tqdm(image_list, desc=f\"Moving files to {dest_img_folder}\"):\n",
    "        src_img = os.path.join(DATASET_DIR, img_file)\n",
    "        dst_img = os.path.join(dest_img_folder, img_file)\n",
    "        shutil.move(src_img, dst_img)\n",
    "\n",
    "        # Move corresponding label file (if exists)\n",
    "        label_file = os.path.splitext(img_file)[0] + \".txt\"\n",
    "        src_label = os.path.join(ANNOTATIONS_DIR, label_file)\n",
    "        dst_label = os.path.join(dest_label_folder, label_file)\n",
    "\n",
    "        if os.path.exists(src_label):\n",
    "            shutil.move(src_label, dst_label)\n",
    "\n",
    "# Move images and labels to respective folders\n",
    "move_files(train_images, TRAIN_DIR, TRAIN_LABELS)\n",
    "move_files(val_images, VAL_DIR, VAL_LABELS)\n",
    "move_files(test_images, TEST_DIR, TEST_LABELS)\n",
    "\n",
    "print(\"âœ… Dataset split into Train, Validation, and Test sets successfully!\")\n",
    "print(f\"ðŸ”¹ Train: {num_train} images\\nðŸ”¹ Val: {num_val} images\\nðŸ”¹ Test: {num_test} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54f81ba0-ff5f-42ab-866a-11e039dc6b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Moving files to images/Training_data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1440/1440 [00:01<00:00, 779.33it/s]\n",
      "Moving files to images/Validation_data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180/180 [00:00<00:00, 636.30it/s]\n",
      "Moving files to images/Testing_data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180/180 [00:00<00:00, 770.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset split into Train, Validation, and Test sets successfully!\n",
      "ðŸ”¹ Train: 1440 images\n",
      "ðŸ”¹ Val: 180 images\n",
      "ðŸ”¹ Test: 180 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define paths\n",
    "DATASET_DIR =  \"Data/NEU-DET/NEU-DET/IMAGES\"\n",
    "\n",
    "ANNOTATIONS_DIR = \"VOC_lab\"  # Folder with YOLO TXT labels\n",
    "\n",
    "# Define new dataset split folders\n",
    "TRAIN_DIR = \"images/Training_data\"\n",
    "VAL_DIR = \"images/Validation_data\"\n",
    "TEST_DIR = \"images/Testing_data\"\n",
    "\n",
    "TRAIN_LABELS = \"labels/Training_data\"\n",
    "VAL_LABELS = \"labels/Validation_data\"\n",
    "TEST_LABELS = \"labels/Testing_data\"\n",
    "\n",
    "# Ensure folders exist\n",
    "for folder in [TRAIN_DIR, VAL_DIR, TEST_DIR, TRAIN_LABELS, VAL_LABELS, TEST_LABELS]:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "# Get all image files\n",
    "image_files = [f for f in os.listdir(DATASET_DIR) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "random.shuffle(image_files)  # Shuffle to randomize split\n",
    "\n",
    "# Define split numbers (Modify as needed)\n",
    "num_train = 1440  # 70% for training\n",
    "num_val = 180   # 20% for validation\n",
    "num_test = 180  # Remaining for test\n",
    "\n",
    "# Assign images to each set\n",
    "train_images = image_files[:num_train]\n",
    "val_images = image_files[num_train:num_train + num_val]\n",
    "test_images = image_files[num_train + num_val:]\n",
    "\n",
    "# Function to move images & annotations\n",
    "def move_files(image_list, dest_img_folder, dest_label_folder):\n",
    "    for img_file in tqdm(image_list, desc=f\"Moving files to {dest_img_folder}\"):\n",
    "        src_img = os.path.join(DATASET_DIR, img_file)\n",
    "        dst_img = os.path.join(dest_img_folder, img_file)\n",
    "        shutil.move(src_img, dst_img)\n",
    "\n",
    "        # Move corresponding label file (if exists)\n",
    "        label_file = os.path.splitext(img_file)[0] + \".txt\"\n",
    "        src_label = os.path.join(ANNOTATIONS_DIR, label_file)\n",
    "        dst_label = os.path.join(dest_label_folder, label_file)\n",
    "\n",
    "        if os.path.exists(src_label):\n",
    "            shutil.move(src_label, dst_label)\n",
    "\n",
    "# Move images and labels to respective folders\n",
    "move_files(train_images, TRAIN_DIR, TRAIN_LABELS)\n",
    "move_files(val_images, VAL_DIR, VAL_LABELS)\n",
    "move_files(test_images, TEST_DIR, TEST_LABELS)\n",
    "\n",
    "print(\"âœ… Dataset split into Train, Validation, and Test sets successfully!\")\n",
    "print(f\"ðŸ”¹ Train: {num_train} images\\nðŸ”¹ Val: {num_val} images\\nðŸ”¹ Test: {num_test} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "610b475e-b748-4227-9dd6-1977cbbc0460",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Annotations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1800/1800 [00:01<00:00, 1432.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Conversion Completed: XML â†’ YOLO format!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define paths\n",
    "VOC_DIR = \"Data/NEU-DET/NEU-DET/ANNOTATIONS\"  # Path where your XML files are stored\n",
    "YOLO_LABELS_DIR = \"VOC_lab\"  # Where YOLO TXT annotations will be saved\n",
    "IMAGE_DIR = \"Data/NEU-DET/NEU-DET/IMAGES\"  # Path where your images are stored\n",
    "\n",
    "# Define class names (Modify according to your dataset)\n",
    "CLASS_NAMES = [\"crazing\", \"inculsion\",\"patches\",\"pitted_surface\",\"rolled_in_scale\",\"scratches\",]\n",
    "\n",
    "# Create labels directory if not exists\n",
    "os.makedirs(YOLO_LABELS_DIR, exist_ok=True)\n",
    "\n",
    "# Function to convert VOC (Pascal) to YOLO format\n",
    "def convert_voc_to_yolo(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Get image dimensions\n",
    "    size = root.find(\"size\")\n",
    "    img_w = int(size.find(\"width\").text)\n",
    "    img_h = int(size.find(\"height\").text)\n",
    "\n",
    "    yolo_txt = \"\"\n",
    "\n",
    "    for obj in root.findall(\"object\"):\n",
    "        class_name = obj.find(\"name\").text\n",
    "        if class_name not in CLASS_NAMES:\n",
    "            continue\n",
    "\n",
    "        class_id = CLASS_NAMES.index(class_name)\n",
    "        bbox = obj.find(\"bndbox\")\n",
    "        x_min = int(bbox.find(\"xmin\").text)\n",
    "        y_min = int(bbox.find(\"ymin\").text)\n",
    "        x_max = int(bbox.find(\"xmax\").text)\n",
    "        y_max = int(bbox.find(\"ymax\").text)\n",
    "\n",
    "        # Convert to YOLO format (normalized values)\n",
    "        x_center = ((x_min + x_max) / 2) / img_w\n",
    "        y_center = ((y_min + y_max) / 2) / img_h\n",
    "        width = (x_max - x_min) / img_w\n",
    "        height = (y_max - y_min) / img_h\n",
    "\n",
    "        yolo_txt += f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\"\n",
    "\n",
    "    return yolo_txt\n",
    "\n",
    "\n",
    "# Process all XML files\n",
    "xml_files = [f for f in os.listdir(VOC_DIR) if f.endswith(\".xml\")]\n",
    "for xml_file in tqdm(xml_files, desc=\"Converting Annotations\"):\n",
    "    xml_path = os.path.join(VOC_DIR, xml_file)\n",
    "    yolo_annotation = convert_voc_to_yolo(xml_path)\n",
    "\n",
    "    if yolo_annotation:\n",
    "        txt_filename = os.path.splitext(xml_file)[0] + \".txt\"\n",
    "        txt_path = os.path.join(YOLO_LABELS_DIR, txt_filename)\n",
    "        with open(txt_path, \"w\") as f:\n",
    "            f.write(yolo_annotation)\n",
    "\n",
    "print(\"âœ… Conversion Completed: XML â†’ YOLO format!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8c7bc0f-6f61-4e8f-98bf-2b152cffe94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Annotations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2294/2294 [00:01<00:00, 1343.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Conversion Completed: XML â†’ YOLO format!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define paths\n",
    "VOC_DIR = \"Data/lable\"  # Path where your XML files are stored\n",
    "YOLO_LABELS_DIR = \"VOC_lab2\"  # Where YOLO TXT annotations will be saved\n",
    "IMAGE_DIR = \"Data/dataset2\"  # Path where your images are stored\n",
    "\n",
    "# Define class names (Modify according to your dataset)\n",
    "CLASS_NAMES = [\"1_chongkong\", \"2_hanfeng\",\"3_yueyawan\",\"4_shuiban\",\"5_youban\",\"6_siban\",\"7_yiwu\",\"8_yahen\",\"9_zhehen\",\"10_yaozhed\"]\n",
    "\n",
    "# Create labels directory if not exists\n",
    "os.makedirs(YOLO_LABELS_DIR, exist_ok=True)\n",
    "\n",
    "# Function to convert VOC (Pascal) to YOLO format\n",
    "def convert_voc_to_yolo(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Get image dimensions\n",
    "    size = root.find(\"size\")\n",
    "    img_w = int(size.find(\"width\").text)\n",
    "    img_h = int(size.find(\"height\").text)\n",
    "\n",
    "    yolo_txt = \"\"\n",
    "\n",
    "    for obj in root.findall(\"object\"):\n",
    "        class_name = obj.find(\"name\").text\n",
    "        if class_name not in CLASS_NAMES:\n",
    "            continue\n",
    "\n",
    "        class_id = CLASS_NAMES.index(class_name)\n",
    "        bbox = obj.find(\"bndbox\")\n",
    "        x_min = int(bbox.find(\"xmin\").text)\n",
    "        y_min = int(bbox.find(\"ymin\").text)\n",
    "        x_max = int(bbox.find(\"xmax\").text)\n",
    "        y_max = int(bbox.find(\"ymax\").text)\n",
    "\n",
    "        # Convert to YOLO format (normalized values)\n",
    "        x_center = ((x_min + x_max) / 2) / img_w\n",
    "        y_center = ((y_min + y_max) / 2) / img_h\n",
    "        width = (x_max - x_min) / img_w\n",
    "        height = (y_max - y_min) / img_h\n",
    "\n",
    "        yolo_txt += f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\"\n",
    "\n",
    "    return yolo_txt\n",
    "\n",
    "\n",
    "# Process all XML files\n",
    "xml_files = [f for f in os.listdir(VOC_DIR) if f.endswith(\".xml\")]\n",
    "for xml_file in tqdm(xml_files, desc=\"Converting Annotations\"):\n",
    "    xml_path = os.path.join(VOC_DIR, xml_file)\n",
    "    yolo_annotation = convert_voc_to_yolo(xml_path)\n",
    "\n",
    "    if yolo_annotation:\n",
    "        txt_filename = os.path.splitext(xml_file)[0] + \".txt\"\n",
    "        txt_path = os.path.join(YOLO_LABELS_DIR, txt_filename)\n",
    "        with open(txt_path, \"w\") as f:\n",
    "            f.write(yolo_annotation)\n",
    "\n",
    "print(\"âœ… Conversion Completed: XML â†’ YOLO format!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d806dc-f279-4fb4-891b-ef4a33e6e5be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
