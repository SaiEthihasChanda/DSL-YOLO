{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "973ea42d-daf8-4dde-b139-9b8a91923835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, average_precision_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b322c996-678b-475b-a287-6e6b7bf3cec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"combined_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "973e9b94-7a18-41ab-872f-f6b28cc77b77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>Corr2</th>\n",
       "      <th>Diss_sim2</th>\n",
       "      <th>Homogen2</th>\n",
       "      <th>Contrast2</th>\n",
       "      <th>Energy3</th>\n",
       "      <th>Corr3</th>\n",
       "      <th>Diss_sim3</th>\n",
       "      <th>Contrast3</th>\n",
       "      <th>Energy4</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000977</td>\n",
       "      <td>0.180385</td>\n",
       "      <td>-0.044725</td>\n",
       "      <td>0.150532</td>\n",
       "      <td>-0.217192</td>\n",
       "      <td>0.663009</td>\n",
       "      <td>0.318875</td>\n",
       "      <td>0.223675</td>\n",
       "      <td>0.251746</td>\n",
       "      <td>-0.094831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957856</td>\n",
       "      <td>5.260471</td>\n",
       "      <td>0.177639</td>\n",
       "      <td>45.961066</td>\n",
       "      <td>0.018837</td>\n",
       "      <td>0.897679</td>\n",
       "      <td>8.187458</td>\n",
       "      <td>111.380737</td>\n",
       "      <td>0.110231</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.195504</td>\n",
       "      <td>0.276669</td>\n",
       "      <td>-0.061317</td>\n",
       "      <td>0.407598</td>\n",
       "      <td>0.260970</td>\n",
       "      <td>0.825568</td>\n",
       "      <td>0.391509</td>\n",
       "      <td>0.583588</td>\n",
       "      <td>0.186765</td>\n",
       "      <td>0.156528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.963605</td>\n",
       "      <td>6.100514</td>\n",
       "      <td>0.159296</td>\n",
       "      <td>64.673783</td>\n",
       "      <td>0.018169</td>\n",
       "      <td>0.922644</td>\n",
       "      <td>8.952959</td>\n",
       "      <td>137.322189</td>\n",
       "      <td>0.103154</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.111006</td>\n",
       "      <td>0.349559</td>\n",
       "      <td>-0.094262</td>\n",
       "      <td>0.216156</td>\n",
       "      <td>0.106058</td>\n",
       "      <td>1.137171</td>\n",
       "      <td>0.201154</td>\n",
       "      <td>0.361343</td>\n",
       "      <td>0.286866</td>\n",
       "      <td>0.052426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.925942</td>\n",
       "      <td>6.688320</td>\n",
       "      <td>0.146016</td>\n",
       "      <td>75.827759</td>\n",
       "      <td>0.017696</td>\n",
       "      <td>0.844452</td>\n",
       "      <td>9.780711</td>\n",
       "      <td>158.963582</td>\n",
       "      <td>0.111965</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.100495</td>\n",
       "      <td>0.275781</td>\n",
       "      <td>-0.116318</td>\n",
       "      <td>0.311098</td>\n",
       "      <td>0.073257</td>\n",
       "      <td>0.908716</td>\n",
       "      <td>0.147829</td>\n",
       "      <td>0.179936</td>\n",
       "      <td>0.280274</td>\n",
       "      <td>0.042768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.909106</td>\n",
       "      <td>6.583259</td>\n",
       "      <td>0.145556</td>\n",
       "      <td>72.746386</td>\n",
       "      <td>0.019040</td>\n",
       "      <td>0.800765</td>\n",
       "      <td>9.790649</td>\n",
       "      <td>159.140659</td>\n",
       "      <td>0.119870</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.049671</td>\n",
       "      <td>0.119182</td>\n",
       "      <td>0.046339</td>\n",
       "      <td>0.119769</td>\n",
       "      <td>0.222893</td>\n",
       "      <td>0.303141</td>\n",
       "      <td>0.084352</td>\n",
       "      <td>0.012266</td>\n",
       "      <td>0.312024</td>\n",
       "      <td>0.056778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.989274</td>\n",
       "      <td>1.503921</td>\n",
       "      <td>0.463249</td>\n",
       "      <td>3.939689</td>\n",
       "      <td>0.046894</td>\n",
       "      <td>0.973307</td>\n",
       "      <td>2.391478</td>\n",
       "      <td>9.771223</td>\n",
       "      <td>0.147577</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14160</th>\n",
       "      <td>0.092375</td>\n",
       "      <td>0.433341</td>\n",
       "      <td>0.148408</td>\n",
       "      <td>-0.140822</td>\n",
       "      <td>0.288990</td>\n",
       "      <td>0.349013</td>\n",
       "      <td>0.209123</td>\n",
       "      <td>-0.004986</td>\n",
       "      <td>0.133768</td>\n",
       "      <td>0.111640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999134</td>\n",
       "      <td>0.163963</td>\n",
       "      <td>0.918022</td>\n",
       "      <td>0.164001</td>\n",
       "      <td>0.128373</td>\n",
       "      <td>0.998540</td>\n",
       "      <td>0.270011</td>\n",
       "      <td>0.276910</td>\n",
       "      <td>0.167666</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14161</th>\n",
       "      <td>-0.019356</td>\n",
       "      <td>0.083175</td>\n",
       "      <td>0.145959</td>\n",
       "      <td>-0.164610</td>\n",
       "      <td>0.223124</td>\n",
       "      <td>0.040336</td>\n",
       "      <td>-0.126574</td>\n",
       "      <td>-0.079431</td>\n",
       "      <td>0.380889</td>\n",
       "      <td>-0.066216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999425</td>\n",
       "      <td>0.041308</td>\n",
       "      <td>0.979346</td>\n",
       "      <td>0.041308</td>\n",
       "      <td>0.212875</td>\n",
       "      <td>0.999053</td>\n",
       "      <td>0.068443</td>\n",
       "      <td>0.068443</td>\n",
       "      <td>0.227692</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14162</th>\n",
       "      <td>-0.124784</td>\n",
       "      <td>0.211899</td>\n",
       "      <td>-0.037131</td>\n",
       "      <td>-0.193507</td>\n",
       "      <td>0.178431</td>\n",
       "      <td>0.097447</td>\n",
       "      <td>0.016363</td>\n",
       "      <td>-0.115176</td>\n",
       "      <td>0.359523</td>\n",
       "      <td>-0.074620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998162</td>\n",
       "      <td>0.377889</td>\n",
       "      <td>0.814976</td>\n",
       "      <td>0.417155</td>\n",
       "      <td>0.097201</td>\n",
       "      <td>0.996178</td>\n",
       "      <td>0.623830</td>\n",
       "      <td>0.867390</td>\n",
       "      <td>0.166726</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14163</th>\n",
       "      <td>0.137629</td>\n",
       "      <td>-0.007763</td>\n",
       "      <td>0.133060</td>\n",
       "      <td>0.196928</td>\n",
       "      <td>0.495559</td>\n",
       "      <td>0.170997</td>\n",
       "      <td>-0.038201</td>\n",
       "      <td>0.133344</td>\n",
       "      <td>0.366415</td>\n",
       "      <td>0.101528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998675</td>\n",
       "      <td>0.262682</td>\n",
       "      <td>0.869234</td>\n",
       "      <td>0.268435</td>\n",
       "      <td>0.134125</td>\n",
       "      <td>0.997359</td>\n",
       "      <td>0.436981</td>\n",
       "      <td>0.536186</td>\n",
       "      <td>0.183026</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14164</th>\n",
       "      <td>0.030705</td>\n",
       "      <td>0.054884</td>\n",
       "      <td>0.155966</td>\n",
       "      <td>0.185381</td>\n",
       "      <td>0.311930</td>\n",
       "      <td>0.157448</td>\n",
       "      <td>0.008960</td>\n",
       "      <td>0.181787</td>\n",
       "      <td>0.257341</td>\n",
       "      <td>0.141640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998976</td>\n",
       "      <td>0.309007</td>\n",
       "      <td>0.845772</td>\n",
       "      <td>0.311761</td>\n",
       "      <td>0.153489</td>\n",
       "      <td>0.997932</td>\n",
       "      <td>0.512631</td>\n",
       "      <td>0.629873</td>\n",
       "      <td>0.207652</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14165 rows × 272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0     -0.000977  0.180385 -0.044725  0.150532 -0.217192  0.663009  0.318875   \n",
       "1      0.195504  0.276669 -0.061317  0.407598  0.260970  0.825568  0.391509   \n",
       "2      0.111006  0.349559 -0.094262  0.216156  0.106058  1.137171  0.201154   \n",
       "3      0.100495  0.275781 -0.116318  0.311098  0.073257  0.908716  0.147829   \n",
       "4     -0.049671  0.119182  0.046339  0.119769  0.222893  0.303141  0.084352   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "14160  0.092375  0.433341  0.148408 -0.140822  0.288990  0.349013  0.209123   \n",
       "14161 -0.019356  0.083175  0.145959 -0.164610  0.223124  0.040336 -0.126574   \n",
       "14162 -0.124784  0.211899 -0.037131 -0.193507  0.178431  0.097447  0.016363   \n",
       "14163  0.137629 -0.007763  0.133060  0.196928  0.495559  0.170997 -0.038201   \n",
       "14164  0.030705  0.054884  0.155966  0.185381  0.311930  0.157448  0.008960   \n",
       "\n",
       "              7         8         9  ...     Corr2  Diss_sim2  Homogen2  \\\n",
       "0      0.223675  0.251746 -0.094831  ...  0.957856   5.260471  0.177639   \n",
       "1      0.583588  0.186765  0.156528  ...  0.963605   6.100514  0.159296   \n",
       "2      0.361343  0.286866  0.052426  ...  0.925942   6.688320  0.146016   \n",
       "3      0.179936  0.280274  0.042768  ...  0.909106   6.583259  0.145556   \n",
       "4      0.012266  0.312024  0.056778  ...  0.989274   1.503921  0.463249   \n",
       "...         ...       ...       ...  ...       ...        ...       ...   \n",
       "14160 -0.004986  0.133768  0.111640  ...  0.999134   0.163963  0.918022   \n",
       "14161 -0.079431  0.380889 -0.066216  ...  0.999425   0.041308  0.979346   \n",
       "14162 -0.115176  0.359523 -0.074620  ...  0.998162   0.377889  0.814976   \n",
       "14163  0.133344  0.366415  0.101528  ...  0.998675   0.262682  0.869234   \n",
       "14164  0.181787  0.257341  0.141640  ...  0.998976   0.309007  0.845772   \n",
       "\n",
       "       Contrast2   Energy3     Corr3  Diss_sim3   Contrast3   Energy4  Target  \n",
       "0      45.961066  0.018837  0.897679   8.187458  111.380737  0.110231       0  \n",
       "1      64.673783  0.018169  0.922644   8.952959  137.322189  0.103154       0  \n",
       "2      75.827759  0.017696  0.844452   9.780711  158.963582  0.111965       0  \n",
       "3      72.746386  0.019040  0.800765   9.790649  159.140659  0.119870       0  \n",
       "4       3.939689  0.046894  0.973307   2.391478    9.771223  0.147577       0  \n",
       "...          ...       ...       ...        ...         ...       ...     ...  \n",
       "14160   0.164001  0.128373  0.998540   0.270011    0.276910  0.167666       5  \n",
       "14161   0.041308  0.212875  0.999053   0.068443    0.068443  0.227692       5  \n",
       "14162   0.417155  0.097201  0.996178   0.623830    0.867390  0.166726       5  \n",
       "14163   0.268435  0.134125  0.997359   0.436981    0.536186  0.183026       5  \n",
       "14164   0.311761  0.153489  0.997932   0.512631    0.629873  0.207652       5  \n",
       "\n",
       "[14165 rows x 272 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop([\"Unnamed: 0\"],axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaa2cddb-b60a-4f03-a587-1e0abfc19d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Target\n",
       "1    4644\n",
       "2    3288\n",
       "5    1888\n",
       "0    1885\n",
       "4    1783\n",
       "3     677\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12e091dd-a39e-42ae-aee8-14c4c105564a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Target\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ebb3476-2e23-47fe-918e-5c9250ccb1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (14165, 271)\n",
      "Reduced shape: (14165, 100)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = df.drop(columns=['Target'])\n",
    "y = df['Target']\n",
    "# X = your feature matrix (excluding target column)\n",
    "# Step 1: Scale the data (very important for PCA!)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Step 2: Apply PCA\n",
    "pca = PCA(n_components=100)  # Retain 95% of variance (OR set a fixed number like 50)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(\"Original shape:\", X.shape)\n",
    "print(\"Reduced shape:\", X_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c78ac9f-8a95-46ef-ad97-4c1886991bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the SVM model\n",
    "model = SVC(kernel='rbf', C=1.0, gamma='scale',probability=True,class_weight='balanced')  # You can change kernel to 'linear', 'poly', etc.\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62098287-367c-4b7b-b0c7-e0e1606de47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ mean Average Precision (mAP): 0.9592258049056822\n"
     ]
    }
   ],
   "source": [
    "y_probs = model.predict_proba(X_train)\n",
    "\n",
    "# 2. Convert y_test to binary format for average_precision_score\n",
    "y_train_bin = label_binarize(y_train, classes=sorted(list(set(y))))\n",
    "\n",
    "# 3. Compute mean Average Precision\n",
    "mAP = average_precision_score(y_train_bin, y_probs, average=\"macro\")\n",
    "print(\"\\n✅ mean Average Precision (mAP):\", mAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d220e93-b13b-4d81-9cf3-1f9991dd1e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 5, 1, ..., 1, 0, 2], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6485a0c6-85c9-4839-848c-6bdda94ffd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9231380162372044\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      1492\n",
      "           1       0.93      0.89      0.91      3696\n",
      "           2       0.90      0.95      0.92      2617\n",
      "           3       0.83      0.96      0.89       551\n",
      "           4       0.97      0.99      0.98      1430\n",
      "           5       0.88      0.85      0.87      1546\n",
      "\n",
      "    accuracy                           0.92     11332\n",
      "   macro avg       0.92      0.93      0.92     11332\n",
      "weighted avg       0.92      0.92      0.92     11332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_train, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ff8df34-12ca-4f23-a446-e423ad96a858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1447,    0,   25,    1,   19,    0],\n",
       "       [   5, 3281,  232,   10,    0,  168],\n",
       "       [  10,    7, 2477,   92,   25,    6],\n",
       "       [   1,    5,   13,  529,    0,    3],\n",
       "       [   0,    4,   11,    4, 1410,    1],\n",
       "       [   0,  221,    4,    3,    1, 1317]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27007e5f-78e7-4ab8-9886-600bd32e8d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.71121631e+00,  5.20186080e+00, -1.21709172e+01, ...,\n",
       "        -2.94505627e-02,  3.45144035e-01,  1.05450633e-01],\n",
       "       [ 1.35782645e+01,  1.47474217e+01,  9.42334441e+00, ...,\n",
       "        -2.24387301e-02,  1.66561261e-01, -2.88825439e-01],\n",
       "       [ 1.55219270e+01,  1.38831670e+01,  1.37819839e-01, ...,\n",
       "         6.42988622e-02, -1.93326843e-01,  2.91391603e-02],\n",
       "       ...,\n",
       "       [-1.09626258e+01, -8.17530173e+00,  1.57517580e+00, ...,\n",
       "        -1.26789338e-01, -4.51287775e-02, -1.48021688e-01],\n",
       "       [-1.45418380e+01,  1.48301918e+01,  1.81446462e+00, ...,\n",
       "         1.44989075e-01, -3.43279757e-01,  1.44158737e-02],\n",
       "       [-1.09278178e+01,  1.25420771e+01,  1.46593310e+00, ...,\n",
       "         1.89395219e-02, -2.54982265e-01, -6.31800067e-02]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7a84bfe-c4bc-495b-bd69-5c28eebfaba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svm_model.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save each component\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "joblib.dump(pca, 'pca.pkl')\n",
    "joblib.dump(model, 'svm_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fefae15a-cf77-4d19-8ff2-e4124eba4f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saiet\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 100 features, but StandardScaler is expecting 271 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvm_model.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Apply same preprocessing\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m X_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[0;32m      9\u001b[0m X_pca \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39mtransform(X_scaled)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Predict\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    322\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:1045\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1042\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1044\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m-> 1045\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m   1046\u001b[0m     X,\n\u001b[0;32m   1047\u001b[0m     reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1048\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1049\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1050\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mFLOAT_DTYPES,\n\u001b[0;32m   1051\u001b[0m     force_writeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1052\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1053\u001b[0m )\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[0;32m   1056\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:654\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 654\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:443\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    446\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 100 features, but StandardScaler is expecting 271 features as input."
     ]
    }
   ],
   "source": [
    "#note to future self, this is how ur supposed to transform ur input as well\n",
    "\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "pca = joblib.load(\"pca.pkl\")\n",
    "model = joblib.load(\"svm_model.pkl\")\n",
    "\n",
    "# Apply same preprocessing\n",
    "X_scaled = scaler.transform(X_test)\n",
    "X_pca = pca.transform(X_scaled)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_pca)\n",
    "print(\"Predictions:\", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011dd948-11cb-4e46-88d3-d183b940420e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
